{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:38:05.081007Z",
     "start_time": "2018-10-03T05:38:04.264881Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:38:05.084882Z",
     "start_time": "2018-10-03T05:38:05.082069Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict\n",
    "import math\n",
    "from models.cnn import CNN\n",
    "from dataloader.cifar10 import DataLoader\n",
    "from utils import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:38:05.185642Z",
     "start_time": "2018-10-03T05:38:05.085863Z"
    }
   },
   "outputs": [],
   "source": [
    "myint = tf.int32\n",
    "myfloat = tf.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:38:05.273996Z",
     "start_time": "2018-10-03T05:38:05.191008Z"
    }
   },
   "outputs": [],
   "source": [
    "config = helper.load_config('./config/bn_both_dropout4.yaml')\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:38:05.732953Z",
     "start_time": "2018-10-03T05:38:05.275209Z"
    }
   },
   "outputs": [],
   "source": [
    "datasource = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:38:05.736180Z",
     "start_time": "2018-10-03T05:38:05.734082Z"
    }
   },
   "outputs": [],
   "source": [
    "print(datasource.data.shape)\n",
    "print(datasource.labels.shape)\n",
    "print(datasource.test_labels.shape)\n",
    "print(datasource.num_step(config['batch_size']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:38:05.837214Z",
     "start_time": "2018-10-03T05:38:05.737145Z"
    }
   },
   "outputs": [],
   "source": [
    "def horizontal_flip(img: np.array, rate: float=0.5):\n",
    "    if rate > np.random.rand():\n",
    "        return img[:, ::-1, :]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:38:06.121733Z",
     "start_time": "2018-10-03T05:38:05.841357Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn = CNN(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:38:06.407306Z",
     "start_time": "2018-10-03T05:38:06.122906Z"
    }
   },
   "outputs": [],
   "source": [
    "crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=cnn.y, logits=cnn.logits)\n",
    "probs_op = tf.nn.softmax(cnn.logits)\n",
    "loss_op = tf.reduce_mean(crossent)\n",
    "optimizer = tf.train.AdamOptimizer(config['learning_rate'])\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train_op = optimizer.minimize(loss_op, global_step=global_step)\n",
    "correct = tf.equal(cnn.predicted_classes, cnn.y)\n",
    "acc_op = tf.reduce_mean(tf.cast(correct, myfloat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:38:06.412551Z",
     "start_time": "2018-10-03T05:38:06.408382Z"
    }
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('train'):\n",
    "    smr_loss = tf.summary.scalar('loss', loss_op)\n",
    "    smr_acc = tf.summary.scalar('accuracy', acc_op)\n",
    "    merged_summary = tf.summary.merge([smr_loss, smr_acc])\n",
    "\n",
    "with tf.name_scope('test'):\n",
    "    test_smr_acc = tf.summary.scalar('accuracy', acc_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:38:06.484172Z",
     "start_time": "2018-10-03T05:38:06.413543Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "logdir_base = 'logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T06:07:34.194136Z",
     "start_time": "2018-10-03T05:38:06.486526Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logdir = logdir_base + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "batch_size = config['batch_size']\n",
    "tf_config = tf.ConfigProto(\n",
    "    allow_soft_placement=True,\n",
    "    gpu_options=tf.GPUOptions(\n",
    "        allow_growth=True\n",
    "    ))\n",
    "with tf.Session(config=tf_config) as sess:\n",
    "    writer = tf.summary.FileWriter(logdir, sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(config['num_epoch']):\n",
    "        step_size = datasource.num_step(batch_size)\n",
    "        for s in range(step_size):\n",
    "            data, labels = datasource.next_batch(batch_size)\n",
    "            data = [horizontal_flip(d) for d in data]\n",
    "            fd = {\n",
    "                cnn.x: data,\n",
    "                cnn.y: labels,\n",
    "                cnn.is_training: True\n",
    "            }\n",
    "            loss, _, acc, smr, step = sess.run([loss_op, train_op, acc_op, merged_summary, global_step], feed_dict=fd)\n",
    "            if step % config['num_print_step'] == 0:\n",
    "                writer.add_summary(smr, step)\n",
    "                #print('{} steps, train accuracy: {:.6f}, loss: {:.6f}'.format(step, acc, loss))\n",
    "                predicted_classes, probs = sess.run([cnn.predicted_classes, probs_op], feed_dict={\n",
    "                    cnn.x: datasource.test_data,\n",
    "                    cnn.is_training: False\n",
    "                })\n",
    "                f_predicted_classes, f_probs = sess.run([cnn.predicted_classes, probs_op], feed_dict={\n",
    "                    cnn.x: [horizontal_flip(d, 1.0) for d in datasource.test_data],\n",
    "                    cnn.is_training: False\n",
    "                })\n",
    "                probs = np.max(probs, axis=1)\n",
    "                f_probs = np.max(f_probs, axis=1)\n",
    "                predicted_labels = np.where(probs >= f_probs, predicted_classes, f_predicted_classes)\n",
    "                #predicted_labels = np.where(probs_label, predicted_classes, f_predicted_classes)\n",
    "                test_acc = np.mean((predicted_labels == datasource.test_labels).astype(np.float32))\n",
    "                test_acc_smr = tf.Summary()\n",
    "                test_acc_smr.value.add(tag='test/accuracy', simple_value=test_acc)\n",
    "                writer.add_summary(test_acc_smr, step)\n",
    "        print('{} steps, test accuracy:  {:.4f}, loss: {:.4f} ({}/{} epochs)'.format(step, test_acc, loss, i, config['num_epoch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T06:07:34.305920Z",
     "start_time": "2018-10-03T06:07:34.197698Z"
    }
   },
   "outputs": [],
   "source": [
    "testimg = datasource.test_data[2]\n",
    "plt.imshow(testimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T06:07:34.386119Z",
     "start_time": "2018-10-03T06:07:34.306914Z"
    }
   },
   "outputs": [],
   "source": [
    "testimg2 = testimg[:,::-1,:]\n",
    "plt.imshow(testimg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
